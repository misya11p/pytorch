{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `state_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `save`\n",
    "\n",
    "[torch.save](https://pytorch.org/docs/stable/generated/torch.save.html)\n",
    "\n",
    "テンソルやモデルの保存。拡張子には`.pt`や`.pth`が基本使われる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "どちらを使うべき、みたいな話は多分なくて、本当にどっちでも良さそう。公式にも\n",
    "\n",
    "> A common PyTorch convention is to save models using either a `.pt` or `.pth` file extension.\n",
    "\n",
    "って書いてある。ただ`.pt`はzopeというwebフレームワークで用いるテンプレートファイルにも使われるようで、一応重複を避けようという気持ちで私は`.pth`を使っている。`.pt`にするとvscodeでテキストファイルのアイコンなんかが出て気持ち悪かったりもする。でもPyTorch公式のexampleでは`.pt`が基本使われているし、copilotが提示するコードも基本`.pt`なので、`.pt`の方が一般的なのかもしれない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "torch.save(x, \"data.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 2)\n",
    "torch.save(model, \"model.pth\") # この使い方はしない方がいい（詳細は後で）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "別にテンソルやモデルでなくてもいい。任意のオブジェクトを保存することができる。pickleと同じ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyObject:\n",
    "    def __init__(self, a, b, c):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"MyObject(a={self.a}, b={self.b}, c={self.c})\"\n",
    "\n",
    "obj = MyObject(1, 2, 3)\n",
    "torch.save(obj, \"obj.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただ、この使い方もしない方がいい。普通にpickle使おう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `load`\n",
    "\n",
    "[torch.load](https://pytorch.org/docs/stable/generated/torch.load.html)\n",
    "\n",
    "保存したファイルを読み込む。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1644820/1216731273.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(\"data.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load(\"data.pth\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1644820/3675544202.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(\"model.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=2, bias=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"model.pth\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1644820/2542391371.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  obj = torch.load(\"obj.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyObject(a=1, b=2, c=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = torch.load(\"obj.pth\")\n",
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファイルは全て読み込めたけど、なんか警告出たな。\n",
    "\n",
    "「今は`weights_only=False`がデフォルトだけど、近いうちに`True`にするから注意してや」って言ってるね。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ちなみに今のバージョンは2.4.0+cu121'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ちなみに今のバージョンは\" + torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`weights_only=True`は、読み込めるオブジェクトをテンソルと辞書（+α）だけにするということ。\n",
    "\n",
    "モデルの保存には二つのやり方があって、一つはさっきやったようにモデルをそのまま保存するやり方。もう一つはモデルの重みだけを保存するやり方で、`model.state_dict()`を使う（詳細は後程）。こうすると重みだけが辞書として保存される。\n",
    "\n",
    "`weights_only=True`だと前者のやり方が使えなくなる。これをデフォルトにすると言っているので、今後は前者を使いたい場合に`weights_only=False`を明示的に指定する必要がある。まあ余程のことがない限り後者を使った方がいいと思うけど。わざわざデフォルト値を変えるということは、そこで問題が起きやすいということなので、大人しく従った方がいい。実際にモデルの保存には`state_dict()`を使うことが推奨されている。\n",
    "\n",
    "> Instead of saving a module directly, for compatibility reasons it is recommended to instead save only its state dict.\n",
    "\n",
    "https://pytorch.org/docs/stable/notes/serialization.html#saving-and-loading-torch-nn-modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `state_dict`\n",
    "\n",
    "[What is a state_dict in PyTorch](https://pytorch.org/tutorials/recipes/recipes/what_is_state_dict.html)\n",
    "\n",
    "モデルパラメータを保存するための辞書。`model.state_dict()`で取得できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.2987,  0.3579,  0.4962],\n",
       "                      [-0.4645,  0.2501, -0.3249]])),\n",
       "             ('bias', tensor([-0.4080,  0.0948]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Linear(3, 2)\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "キーが属性名、値はテンソル。\n",
    "\n",
    "`OrderedDict`というオブジェクトで、通常の辞書とは違い、順序が保持される。`collections`という標準モジュールの機能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの保存・読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルを保存するときはこの辞書を保存することが推奨されている。保存したいのはパラメータだけなのでこれでよい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(3, 2)\n",
    "        self.fc2 = nn.Linear(2, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel()\n",
    "state_dict = model.state_dict()\n",
    "torch.save(state_dict, \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`state_dict`を読み込むときは`load_state_dict()`を使う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel()\n",
    "state_dict = torch.load(\"model.pth\", weights_only=True)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "キーが足りなかったり余分なキーがあったりするとエラーが出る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error(s) in loading state_dict for MyModel:\n",
      "\tMissing key(s) in state_dict: \"fc2.weight\". \n",
      "\tUnexpected key(s) in state_dict: \"fc1234.weight\". \n"
     ]
    }
   ],
   "source": [
    "state_dict_incorrect = state_dict.copy()\n",
    "state_dict_incorrect.pop(\"fc2.weight\")\n",
    "state_dict_incorrect[\"fc1234.weight\"] = torch.tensor([1, 2, 3, 4])\n",
    "try:\n",
    "    model.load_state_dict(state_dict_incorrect)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`strict=False`を指定すると勝手に無視して読み込んでくれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['fc2.weight'], unexpected_keys=['fc1234.weight'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict_incorrect, strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正しいキーで間違った値を入れると、いかなる場合でもエラーを出してくれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error(s) in loading state_dict for MyModel:\n",
      "\tsize mismatch for fc2.weight: copying a param with shape torch.Size([5]) from checkpoint, the shape in current model is torch.Size([1, 2]).\n"
     ]
    }
   ],
   "source": [
    "state_dict_incorrect = state_dict.copy()\n",
    "state_dict_incorrect[\"fc2.weight\"] = torch.tensor([99, 99, 99, 99, 99])\n",
    "try:\n",
    "    model.load_state_dict(state_dict_incorrect, strict=False)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "読み込む辞書のキーと同じ名前（属性）のパラメータをモデルが保有している必要がある。だから、例えば変数名を変えたりしてもエラーが出る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error(s) in loading state_dict for MyModel2:\n",
      "\tMissing key(s) in state_dict: \"fc_1.weight\", \"fc_1.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"fc1.weight\", \"fc1.bias\". \n"
     ]
    }
   ],
   "source": [
    "class MyModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.fc1 = nn.Linear(3, 2)\n",
    "        self.fc_1 = nn.Linear(3, 2) # アンダースコアを付けた\n",
    "        self.fc2 = nn.Linear(2, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel2()\n",
    "try:\n",
    "    model.load_state_dict(state_dict)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### デバイス\n",
    "\n",
    "`torch.Tensor`はデバイスの情報を持つ。モデルパラメータも`torch.Tensor`なので、当然、モデルパラメータもデバイスの情報を持つ。\n",
    "\n",
    "`state_dict`で得たパラメータにもデバイスの情報が乗っている。`state_dict()`を呼び出す際のモデルのデバイスと同じものが乗る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.4732,  0.4301,  0.1034],\n",
       "                      [ 0.3597,  0.1872, -0.0266]], device='cuda:0')),\n",
       "             ('fc1.bias', tensor([-0.2967,  0.3656], device='cuda:0')),\n",
       "             ('fc2.weight', tensor([[ 0.5535, -0.5524]], device='cuda:0')),\n",
       "             ('fc2.bias', tensor([0.1616], device='cuda:0'))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda = torch.device(\"cuda\")\n",
    "model = MyModel()\n",
    "model.to(cuda)\n",
    "state_dict = model.state_dict()\n",
    "torch.save(state_dict, \"model.pth\")\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これを読み込むと、当然同じデバイスでパラメータが読み込まれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.4732,  0.4301,  0.1034],\n",
       "                      [ 0.3597,  0.1872, -0.0266]], device='cuda:0')),\n",
       "             ('fc1.bias', tensor([-0.2967,  0.3656], device='cuda:0')),\n",
       "             ('fc2.weight', tensor([[ 0.5535, -0.5524]], device='cuda:0')),\n",
       "             ('fc2.bias', tensor([0.1616], device='cuda:0'))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"model.pth\", weights_only=True)\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`map_location`で読み込む際のデバイスを指定できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.4732,  0.4301,  0.1034],\n",
       "                      [ 0.3597,  0.1872, -0.0266]])),\n",
       "             ('fc1.bias', tensor([-0.2967,  0.3656])),\n",
       "             ('fc2.weight', tensor([[ 0.5535, -0.5524]])),\n",
       "             ('fc2.bias', tensor([0.1616]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu = torch.device(\"cpu\")\n",
    "state_dict = torch.load(\"model.pth\", weights_only=True, map_location=cpu)\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルに読み込む場合は、そのモデルのデバイスに合わせて読み込まれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MyModel() # CPUに作成\n",
    "state_dict = torch.load(\"model.pth\", weights_only=True, map_location=cuda) # GPUに読み込み\n",
    "model.load_state_dict(state_dict)\n",
    "model.fc1.weight.device # CPUに読み込まれる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルがGPUにあるときはGPUに読み込まれる\n",
    "model = MyModel()\n",
    "model.to(cuda)\n",
    "model.load_state_dict(state_dict)\n",
    "model.fc1.weight.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.compile`\n",
    "\n",
    "`torch.compile`をした後はキーに注意しないといけない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): MyModel(\n",
       "    (fc1): Linear(in_features=3, out_features=2, bias=True)\n",
       "    (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.compile(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与えたモデルが`_orig_mod`としてまとめられている。つまりこれの`state_dict`は"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('_orig_mod.fc1.weight',\n",
       "              tensor([[ 0.4732,  0.4301,  0.1034],\n",
       "                      [ 0.3597,  0.1872, -0.0266]], device='cuda:0')),\n",
       "             ('_orig_mod.fc1.bias',\n",
       "              tensor([-0.2967,  0.3656], device='cuda:0')),\n",
       "             ('_orig_mod.fc2.weight',\n",
       "              tensor([[ 0.5535, -0.5524]], device='cuda:0')),\n",
       "             ('_orig_mod.fc2.bias', tensor([0.1616], device='cuda:0'))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こうなる。全てのキーに`_orig_mod.`がついている。これを読み込む場合、compile済みのモデルに読み込む必要がある。それは少々不便なので、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.4732,  0.4301,  0.1034],\n",
       "                      [ 0.3597,  0.1872, -0.0266]], device='cuda:0')),\n",
       "             ('fc1.bias', tensor([-0.2967,  0.3656], device='cuda:0')),\n",
       "             ('fc2.weight', tensor([[ 0.5535, -0.5524]], device='cuda:0')),\n",
       "             ('fc2.bias', tensor([0.1616], device='cuda:0'))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._orig_mod.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "とする。こうすれば`_orig_mod.`がつかない。\n",
    "\n",
    "ただこれはcompile済みのモデルにしか使えない。compile前でも後でも良いようにするには以下の通り。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.4732,  0.4301,  0.1034],\n",
       "                      [ 0.3597,  0.1872, -0.0266]], device='cuda:0')),\n",
       "             ('fc1.bias', tensor([-0.2967,  0.3656], device='cuda:0')),\n",
       "             ('fc2.weight', tensor([[ 0.5535, -0.5524]], device='cuda:0')),\n",
       "             ('fc2.bias', tensor([0.1616], device='cuda:0'))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(model, \"_orig_mod\", model).state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_orig_mod`属性を持っていればそれ、なければそのまま。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
