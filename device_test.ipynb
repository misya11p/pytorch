{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# デバイスによる演算結果の違いについての検証\n",
    "\n",
    "mpsを使うと学習が上手くいかないので検証する．\n",
    "\n",
    "適当にGANを作ってみる"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from IPython.display import display\n",
    "\n",
    "batch_size = 64\n",
    "nz = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(batch_size, device):\n",
    "    return torch.randn(batch_size, nz, 1, 1).to(device)\n",
    "\n",
    "def write(netG, device, n_rows=1, n_cols=8, size=64):\n",
    "    z = make_noise(n_rows*n_cols, device)\n",
    "    images = netG(z)\n",
    "    images = transforms.Resize(size)(images)\n",
    "    img = torchvision.utils.make_grid(images, n_cols)\n",
    "    img = transforms.functional.to_pil_image(img)\n",
    "    display(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch shape:  torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "dataset = MNIST(\n",
    "    root=\"data/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "sample_x, _ = next(iter(dataloader))\n",
    "print(\"batch shape: \", sample_x.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            self._conv(1, 16, 4, 2, 1),\n",
    "            self._conv(16, 32, 4, 2, 1),\n",
    "            self._conv(32, 64, 3, 2, 0),\n",
    "            nn.Conv2d(64, 128, 3, 1, 0),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def _conv(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            self._convT(nz, 128, 3, 1, 0),\n",
    "            self._convT(128, 64, 3, 2, 0),\n",
    "            self._convT(64, 32, 4, 2, 1),\n",
    "            nn.ConvTranspose2d(32, 1, 4, 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _convT(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.net(x)\n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 学習 (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(124)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = Discriminator().to(device)\n",
    "netG = Generator(nz).to(device)\n",
    "optimD = optim.Adam(netD.parameters(), lr=0.0002)\n",
    "optimG = optim.Adam(netG.parameters(), lr=0.0002)\n",
    "\n",
    "fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "real_labels = torch.ones(batch_size, 1).to(device)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_netG_weight_cpu = netG.net[0][0].weight[0, 0].detach().clone()\n",
    "pre_netD_weight_cpu = netD.net[0][0].weight[0, 0].detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = 100\n",
    "\n",
    "for i, (X, _) in enumerate(dataloader):\n",
    "    X = X.to(device)\n",
    "    optimD.zero_grad()\n",
    "    optimG.zero_grad()\n",
    "\n",
    "    z = make_noise(batch_size, device)\n",
    "    fake = netG(z)\n",
    "    pred_fake = netD(fake)\n",
    "    pred_real = netD(X)\n",
    "    loss_fake = criterion(pred_fake, fake_labels)\n",
    "    loss_real = criterion(pred_real, real_labels)\n",
    "    lossD = loss_fake + loss_real\n",
    "    lossD.backward()\n",
    "    optimD.step()\n",
    "\n",
    "    fake = netG(z)\n",
    "    pred = netD(fake)\n",
    "    lossG = criterion(pred, real_labels)\n",
    "    lossG.backward()\n",
    "    optimG.step()\n",
    "\n",
    "    if i >= lim:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_weight_cpu = netG.net[0][0].weight[0, 0].detach().clone()\n",
    "netD_weight_cpu = netD.net[0][0].weight[0, 0].detach().clone()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 学習 (mps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(124)\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = Discriminator().to(device)\n",
    "netG = Generator(nz).to(device)\n",
    "optimD = optim.Adam(netD.parameters(), lr=0.0002)\n",
    "optimG = optim.Adam(netG.parameters(), lr=0.0002)\n",
    "\n",
    "fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "real_labels = torch.ones(batch_size, 1).to(device)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_netG_weight_mps = netG.net[0][0].weight[0, 0].detach().clone()\n",
    "pre_netD_weight_mps = netD.net[0][0].weight[0, 0].detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = 10\n",
    "\n",
    "for i, (X, _) in enumerate(dataloader):\n",
    "    X = X.to(device)\n",
    "    optimD.zero_grad()\n",
    "    optimG.zero_grad()\n",
    "\n",
    "    z = make_noise(batch_size, device)\n",
    "    fake = netG(z)\n",
    "    pred_fake = netD(fake)\n",
    "    pred_real = netD(X)\n",
    "    loss_fake = criterion(pred_fake, fake_labels)\n",
    "    loss_real = criterion(pred_real, real_labels)\n",
    "    lossD = loss_fake + loss_real\n",
    "    lossD.backward()\n",
    "    optimD.step()\n",
    "\n",
    "    fake = netG(z)\n",
    "    pred = netD(fake)\n",
    "    lossG = criterion(pred, real_labels)\n",
    "    lossG.backward()\n",
    "    optimG.step()\n",
    "\n",
    "    if i >= lim:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG_weight_mps = netG.net[0][0].weight[0, 0].detach().clone()\n",
    "netD_weight_mps = netD.net[0][0].weight[0, 0].detach().clone()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 結果\n",
    "\n",
    "CPUとmpsで学習したモデルの重み（の一部）を比較する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習前の生成器\n",
      "CPU:   0.0043 -0.0239 -0.0005  0.0243  0.0112  0.0217  0.0083 -0.0101  0.0203\n",
      "mps:   0.0043 -0.0239 -0.0005  0.0243  0.0112  0.0217  0.0083 -0.0101  0.0203\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "学習後の生成器\n",
      "CPU:   0.0045 -0.0292  0.0041  0.0176  0.0227  0.0148  0.0046 -0.0038  0.0267\n",
      "mps:   0.0029 -0.0257 -0.0005  0.0230  0.0115  0.0220  0.0079 -0.0113  0.0211\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "学習前の識別器\n",
      "CPU:  -0.1737  0.0656  0.1703 -0.0129  0.0061 -0.1885 -0.0951 -0.0168 -0.0076 -0.1392 -0.1794 -0.0265  0.2492  0.2102 -0.1292  0.0305\n",
      "mps:  -0.1737  0.0656  0.1703 -0.0129  0.0061 -0.1885 -0.0951 -0.0168 -0.0076 -0.1392 -0.1794 -0.0265  0.2492  0.2102 -0.1292  0.0305\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "学習後の識別器\n",
      "CPU:  -0.1730  0.0702  0.1522  0.0035  0.0100 -0.2024 -0.1137 -0.0245 -0.0063 -0.1575 -0.1773 -0.0309  0.2451  0.2154 -0.1196  0.0180\n",
      "mps:  -0.1746  0.0675  0.1697 -0.0109  0.0042 -0.1901 -0.0970 -0.0184 -0.0098 -0.1409 -0.1810 -0.0278  0.2472  0.2080 -0.1311  0.0286\n"
     ]
    }
   ],
   "source": [
    "def format_weights(weights):\n",
    "    return \" \".join(map(lambda x: f\"{x:>7.4f}\", weights.ravel().tolist()))\n",
    "line = lambda : print('-'*150)\n",
    "\n",
    "print(\"学習前の生成器\")\n",
    "print(\"CPU: \", format_weights(pre_netG_weight_cpu))\n",
    "print(\"mps: \", format_weights(pre_netG_weight_mps))\n",
    "\n",
    "line()\n",
    "\n",
    "print(\"学習後の生成器\")\n",
    "print(\"CPU: \", format_weights(netG_weight_cpu))\n",
    "print(\"mps: \", format_weights(netG_weight_mps))\n",
    "\n",
    "line()\n",
    "\n",
    "print(\"学習前の識別器\")\n",
    "print(\"CPU: \", format_weights(pre_netD_weight_cpu))\n",
    "print(\"mps: \", format_weights(pre_netD_weight_mps))\n",
    "\n",
    "line()\n",
    "\n",
    "print(\"学習後の識別器\")\n",
    "print(\"CPU: \", format_weights(netD_weight_cpu))\n",
    "print(\"mps: \", format_weights(netD_weight_mps))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習前はちゃんと同じ値になっているが，学習後は少し誤差が生じている．\n",
    "\n",
    "学習が上手くいかないのは，この誤差が結構致命的なものになっているからなのかな．\n",
    "\n",
    "<br>\n",
    "\n",
    "GPUによる演算の誤差について\n",
    "- [ChainerやTensorFlowでGPUを使うと毎回結果が変わる理由と対策 (まとめ) - Qiita](https://qiita.com/TokyoMickey/items/63c4053740ab1f3f28a2a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37ed3b1c5e2780b0e8a5da5fb8b92ea58c827ecdcf5d33315c46ca232b094762"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
